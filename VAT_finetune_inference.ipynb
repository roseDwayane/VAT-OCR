{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edcc16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Exception in thread Thread-4 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa4 in position 7: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0921 16:14:42.529000 24812 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:339: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:35.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE}:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.4: Fast Qwen2_5_Vl patching. Transformers: 4.56.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070. Num GPUs = 1. Max memory: 11.994 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from unsloth import FastVisionModel\n",
    "    model, tokenizer = FastVisionModel.from_pretrained(\n",
    "        model_name = \"VAT_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        load_in_4bit = True, # Set to False for 16bit LoRA\n",
    "    )\n",
    "    FastVisionModel.for_inference(model) # Enable for inference!\n",
    "\n",
    "import re, json, ast\n",
    "from typing import Tuple, Any, List, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6249f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def repair_json(s: str, schema: Optional[dict] = None) -> Tuple[str, Any, List[str]]:\n",
    "    \"\"\"\n",
    "    將「幾乎 JSON」的字串修復成合法 JSON。\n",
    "    回傳: (fixed_text, obj, logs)\n",
    "      fixed_text: 修復後的 JSON 字串\n",
    "      obj:        對應的 Python 物件 (dict/list)\n",
    "      logs:       修復步驟紀錄\n",
    "    \"\"\"\n",
    "    logs: List[str] = []\n",
    "    text = s.strip()\n",
    "\n",
    "    # 0) 去掉 ```json ... ``` 或一般 ``` 區塊外殼\n",
    "    if \"```\" in text:\n",
    "        text = re.sub(r\"```(?:json|JSON)?\", \"\", text)\n",
    "        text = text.replace(\"```\", \"\")\n",
    "        text = text.strip()\n",
    "        logs.append(\"removed code fences\")\n",
    "\n",
    "    # 1) 只擷取最外層 {...} 或 [...]\n",
    "    def _extract_json_region(t: str) -> str:\n",
    "        lb, rb = t.find(\"{\"), t.rfind(\"}\")\n",
    "        if lb != -1 and rb != -1 and rb > lb:\n",
    "            return t[lb:rb+1]\n",
    "        lb, rb = t.find(\"[\"), t.rfind(\"]\")\n",
    "        if lb != -1 and rb != -1 and rb > lb:\n",
    "            return t[lb:rb+1]\n",
    "        return t\n",
    "\n",
    "    text2 = _extract_json_region(text)\n",
    "    if text2 != text:\n",
    "        logs.append(\"extracted outer JSON-like region\")\n",
    "        text = text2\n",
    "\n",
    "    # 2) 嘗試標準 JSON\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        logs.append(\"parsed by json\")\n",
    "        if schema:\n",
    "            from jsonschema import validate\n",
    "            validate(obj, schema); logs.append(\"validated by jsonschema\")\n",
    "        return json.dumps(obj, ensure_ascii=False, indent=2), obj, logs\n",
    "    except Exception as e:\n",
    "        logs.append(f\"json.loads failed: {e}\")\n",
    "\n",
    "    # 3) 用 ast.literal_eval 吃單引號/尾逗號 等 Python 字面量\n",
    "    try:\n",
    "        obj = ast.literal_eval(text)\n",
    "        logs.append(\"parsed by ast.literal_eval\")\n",
    "        if schema:\n",
    "            from jsonschema import validate\n",
    "            validate(obj, schema); logs.append(\"validated by jsonschema\")\n",
    "        return json.dumps(obj, ensure_ascii=False, indent=2), obj, logs\n",
    "    except Exception as e:\n",
    "        logs.append(f\"ast.literal_eval failed: {e}\")\n",
    "\n",
    "    # 4) 常見修補：彎引號→直引號、True/False/None→JSON、刪尾逗號、單引號→雙引號\n",
    "    fixed = text.translate(str.maketrans({\n",
    "        \"\\u201c\": '\"', \"\\u201d\": '\"', \"\\u2018\": \"'\", \"\\u2019\": \"'\",\n",
    "    }))\n",
    "    if fixed != text:\n",
    "        logs.append(\"normalized curly quotes\")\n",
    "\n",
    "    # Python 常量 → JSON 常量\n",
    "    fixed2 = re.sub(r'(?<!\")\\bTrue\\b(?!\")', \"true\", fixed)\n",
    "    fixed2 = re.sub(r'(?<!\")\\bFalse\\b(?!\")', \"false\", fixed2)\n",
    "    fixed2 = re.sub(r'(?<!\")\\bNone\\b(?!\")', \"null\", fixed2)\n",
    "    if fixed2 != fixed:\n",
    "        logs.append(\"converted Python literals to JSON\")\n",
    "    fixed = fixed2\n",
    "\n",
    "    # 移除尾逗號\n",
    "    no_trailing_commas = re.sub(r\",\\s*([}\\]])\", r\"\\1\", fixed)\n",
    "    if no_trailing_commas != fixed:\n",
    "        logs.append(\"removed trailing commas\")\n",
    "    fixed = no_trailing_commas\n",
    "\n",
    "    # 粗略：單引號 → 雙引號（在中文內容通常安全）\n",
    "    dq = re.sub(r\"(?<!\\\\)'\", '\"', fixed)\n",
    "    if dq != fixed:\n",
    "        logs.append(\"replaced single quotes with double quotes\")\n",
    "    fixed = dq\n",
    "\n",
    "    # 5) 最終嘗試標準 JSON\n",
    "    try:\n",
    "        obj = json.loads(fixed)\n",
    "        logs.append(\"fixed manually then parsed by json\")\n",
    "        if schema:\n",
    "            from jsonschema import validate\n",
    "            validate(obj, schema); logs.append(\"validated by jsonschema\")\n",
    "        return json.dumps(obj, ensure_ascii=False, indent=2), obj, logs\n",
    "    except Exception as e:\n",
    "        logs.append(f\"final json.loads failed: {e}\")\n",
    "        # 兜底：包 raw\n",
    "        fallback = {\"raw\": s}\n",
    "        if schema:\n",
    "            logs.append(\"returned raw because schema validation/parse failed\")\n",
    "        return json.dumps(fallback, ensure_ascii=False, indent=2), fallback, logs\n",
    "\n",
    "import json, re\n",
    "from typing import Any, Dict, Tuple, Mapping, Optional\n",
    "\n",
    "def _extract_json(s: str) -> Dict[str, Any]:\n",
    "    start = s.find(\"{\"); end = s.rfind(\"}\")\n",
    "    if start == -1 or end == -1 or end < start:\n",
    "        raise ValueError(\"找不到可解析的 JSON 內容\")\n",
    "    return json.loads(s[start:end+1])\n",
    "\n",
    "def _canonical_key_map(d: Dict[str, Any]) -> Dict[str, str]:\n",
    "    # 建立不分大小寫的鍵名映射：lower(key) -> 原鍵名\n",
    "    return {k.lower(): k for k in d.keys()}\n",
    "\n",
    "def _get_ci(d: Dict[str, Any], key: str):\n",
    "    # 不分大小寫取值；找不到返回 None\n",
    "    if key in d: return d[key]\n",
    "    lk = key.lower()\n",
    "    for k in d.keys():\n",
    "        if k.lower() == lk:\n",
    "            return d[k]\n",
    "    return None\n",
    "\n",
    "def _is_none(x: Any) -> bool: return x is None\n",
    "def _is_nonempty_str(x: Any) -> bool: return isinstance(x, str) and len(x.strip()) > 0\n",
    "def _re_match(pattern: str, x: Any) -> bool:\n",
    "    if x is None: return True          # 非必填且 None 視為 OK；是否必填由 required 控制\n",
    "    if not isinstance(x, str): return False\n",
    "    return re.fullmatch(pattern, x.strip()) is not None\n",
    "\n",
    "def _amount_parse_and_normalize_int_str(x: Any) -> Optional[str]:\n",
    "    \"\"\"允許千分位與 .00；回傳正規化整數字串，否則 None。\"\"\"\n",
    "    if not isinstance(x, str) or not x.strip():\n",
    "        return None\n",
    "    s = x.strip()\n",
    "    # 允許 \"123456\", \"1,234,567\", \"1,234,567.00\"\n",
    "    if re.fullmatch(r\"\\d{1,3}(,\\d{3})*(?:\\.00)?\", s):\n",
    "        s_no_comma = s.replace(\",\", \"\")\n",
    "        if s_no_comma.endswith(\".00\"):\n",
    "            s_no_comma = s_no_comma[:-3]\n",
    "        try:\n",
    "            return str(int(s_no_comma))\n",
    "        except ValueError:\n",
    "            return None\n",
    "    # 允許無逗號但帶 .00\n",
    "    if re.fullmatch(r\"\\d+(?:\\.00)?\", s):\n",
    "        if s.endswith(\".00\"):\n",
    "            s = s[:-3]\n",
    "        try:\n",
    "            return str(int(s))\n",
    "        except ValueError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "def _normalize_year_to_gregorian(y: Any) -> Optional[str]:\n",
    "    \"\"\"2~3 碼視為民國年 +1911；4 碼視為西元年；其餘回 None。\"\"\"\n",
    "    if not isinstance(y, str) or not y.strip() or not y.strip().isdigit():\n",
    "        return None\n",
    "    s = y.strip()\n",
    "    if len(s) in (2, 3):  # 民國年\n",
    "        return str(int(s) + 1911)\n",
    "    if len(s) == 4:       # 西元年\n",
    "        return s\n",
    "    return None\n",
    "\n",
    "\n",
    "def _strip_leading_zero_num_str(x: Any) -> Optional[str]:\n",
    "    \"\"\"將 '09' -> '9'；若非數字字串則回 None。\"\"\"\n",
    "    if not isinstance(x, str) or not x.strip():\n",
    "        return None\n",
    "    s = x.strip()\n",
    "    if not re.fullmatch(r\"\\d+\", s):\n",
    "        return None\n",
    "    try:\n",
    "        return str(int(s))\n",
    "    except ValueError:\n",
    "        return None\n",
    "\n",
    "PAT_MM = r\"(0?[1-9]|1[0-2])\"\n",
    "PAT_DD = r\"(0?[1-9]|[12]\\d|3[01])\"\n",
    "\n",
    "def check_compliance(\n",
    "    data_or_str: Any,\n",
    "    required_fields: Optional[Tuple[str, ...]] = None,\n",
    "    required_fields_by_doc_class: Optional[Mapping[str, Tuple[str, ...]]] = None,\n",
    "    only_required_and_rules: bool = True,\n",
    "    emit_info: bool = True,  # 若要加上 @info，可設 True\n",
    "    emit_normalized: bool = False,                  # ★ 會輸出 @normalized:*（三個金額欄位）\n",
    "    return_normalized_object: bool = True,        # ★ 回傳 (結果, 正規化後物件)\n",
    ") -> Dict[str, bool]:\n",
    "    # 1) 解析\n",
    "    if isinstance(data_or_str, str):\n",
    "        obj = _extract_json(data_or_str)\n",
    "    elif isinstance(data_or_str, dict):\n",
    "        obj = data_or_str\n",
    "    else:\n",
    "        raise TypeError(\"只接受 dict 或 str (JSON)\")\n",
    "\n",
    "    # 2) 取出扁平的 gt_parse（若不在 gt_parse，則視為已是扁平）\n",
    "    root = obj.get(\"gt_parse\", obj)\n",
    "    keymap = _canonical_key_map(root)\n",
    "    # 支援 Doc_class / doc_class；Rationale / rationale\n",
    "    doc_class_key = keymap.get(\"doc_class\", \"Doc_class\" if \"Doc_class\" in root else \"doc_class\")\n",
    "    rationale_key = keymap.get(\"rationale\", \"Rationale\" if \"Rationale\" in root else \"rationale\")\n",
    "    doc_class = _get_ci(root, doc_class_key)\n",
    "\n",
    "    # 3) 欄位格式規則（扁平版）\n",
    "    rules = {\n",
    "        \"PrefixTwoLetters\":    lambda v: _re_match(r\"[A-Z]{2}\", v),\n",
    "        \"InvoiceNumber\":       lambda v: _re_match(r\"\\d{8}\", v),\n",
    "        \"InvoiceYear\":         lambda v: _re_match(r\"(\\d{2,3}|\\d{4})\", v),\n",
    "        \"InvoiceMonth\":        lambda v: _re_match(r\"(0?[1-9]|1[0-2])\", v),\n",
    "        \"InvoiceDay\":          lambda v: _re_match(r\"(0?[1-9]|[12]\\d|3[01])\", v),\n",
    "        \"BuyerName\":           lambda v: True if v is None else _is_nonempty_str(v),\n",
    "        \"BuyerTaxIDNumber\":    lambda v: True if v is None else _re_match(r\"\\d{8}\", v),\n",
    "        \"CompanyName\":         lambda v: True if v is None else _is_nonempty_str(v),\n",
    "        \"CompanyAddress\":      lambda v: True if v is None else _is_nonempty_str(v),\n",
    "        \"CompanyTaxIDNumber\":  lambda v: True if v is None else _re_match(r\"\\d{8}\", v),\n",
    "        \"PhoneNumber\":         lambda v: True if v is None else _re_match(r\"[0-9()+\\- ]{7,}\", v),\n",
    "        \"Abstract\":            lambda v: True if v is None else _is_nonempty_str(v),\n",
    "        \"SalesTotalAmount\":    lambda v: (_amount_parse_and_normalize_int_str(v) is not None),\n",
    "        \"SalesTax\":            lambda v: (_amount_parse_and_normalize_int_str(v) is not None),\n",
    "        \"TotalAmount\":         lambda v: (_amount_parse_and_normalize_int_str(v) is not None),\n",
    "        # meta\n",
    "        doc_class_key:         lambda v: _is_nonempty_str(v) if v is not None else True,\n",
    "        rationale_key:         lambda v: True if v is None else _is_nonempty_str(v),\n",
    "    }\n",
    "\n",
    "    # 4) 平面值（用輸入的實際鍵名；找不到就是 None）\n",
    "    values = { k: root.get(k) for k in [\n",
    "        \"PrefixTwoLetters\",\"InvoiceNumber\",\"InvoiceYear\",\"InvoiceMonth\",\"InvoiceDay\",\n",
    "        \"BuyerName\",\"BuyerTaxIDNumber\",\"CompanyName\",\"CompanyAddress\",\"CompanyTaxIDNumber\",\n",
    "        \"PhoneNumber\",\"Abstract\",\"SalesTotalAmount\",\"SalesTax\",\"TotalAmount\",\n",
    "    ]}\n",
    "    values[doc_class_key] = doc_class\n",
    "    values[rationale_key] = _get_ci(root, rationale_key)\n",
    "\n",
    "    # 5) 必填欄位（扁平版；可依需求調整）\n",
    "    default_required = required_fields or (\n",
    "        \"PrefixTwoLetters\",\"InvoiceNumber\",\"SalesTotalAmount\",\"SalesTax\",\"TotalAmount\",\n",
    "    )\n",
    "    per_class_required = required_fields_by_doc_class or {\n",
    "        \"triple_invoice\": (\n",
    "            \"PrefixTwoLetters\",\"InvoiceNumber\", \"BuyerTaxIDNumber\",\n",
    "            \"InvoiceYear\",\"InvoiceMonth\",\"InvoiceDay\", \"Abstract\",\n",
    "            \"SalesTotalAmount\",\"SalesTax\",\"TotalAmount\", \"CompanyTaxIDNumber\",\n",
    "        ),\n",
    "        \"triple_receipt\": (\n",
    "            \"PrefixTwoLetters\",\"InvoiceNumber\", \"CompanyTaxIDNumber\",\n",
    "            \"InvoiceYear\",\"InvoiceMonth\",\"InvoiceDay\", \"BuyerTaxIDNumber\",\n",
    "            \"Abstract\",\n",
    "            \"SalesTotalAmount\",\"SalesTax\",\"TotalAmount\",\n",
    "        ),\n",
    "    }\n",
    "    active_required = per_class_required.get(str(doc_class), default_required)\n",
    "\n",
    "    # 基本 + 必填\n",
    "    full_result: Dict[str, bool] = {}\n",
    "    for key, val in values.items():\n",
    "        validator = rules.get(key, lambda v: True)\n",
    "        ok = validator(val)\n",
    "        if ok and key in active_required:\n",
    "            ok = not _is_none(val) and (not isinstance(val, str) or len(val.strip()) > 0)\n",
    "        full_result[key] = bool(ok)\n",
    "\n",
    "    # 合計規則：以正規化後數值進行\n",
    "    def _to_int_from_amount(x: Any) -> Optional[int]:\n",
    "        norm = _amount_parse_and_normalize_int_str(x)\n",
    "        if norm is not None:\n",
    "            return int(norm)\n",
    "        if isinstance(x, str) and re.fullmatch(r\"\\d+\", x or \"\"):\n",
    "            return int(x)\n",
    "        return None\n",
    "\n",
    "    st = _to_int_from_amount(values.get(\"SalesTotalAmount\"))\n",
    "    tax = _to_int_from_amount(values.get(\"SalesTax\"))\n",
    "    total = _to_int_from_amount(values.get(\"TotalAmount\"))\n",
    "    if None not in (st, tax, total):\n",
    "        full_result[\"@rule:TotalAmount_equals_SalesTotal_plus_SalesTax\"] = (st + tax == total)\n",
    "\n",
    "    # 正規化輸出與物件（依 doc_class 組出「固定欄位 + 固定順序」）\n",
    "    # 1) 先準備各欄位的正規化值\n",
    "    st_norm = _amount_parse_and_normalize_int_str(values.get(\"SalesTotalAmount\"))\n",
    "    tax_norm = _amount_parse_and_normalize_int_str(values.get(\"SalesTax\"))\n",
    "    total_norm = _amount_parse_and_normalize_int_str(values.get(\"TotalAmount\"))\n",
    "    year_norm = _normalize_year_to_gregorian(values.get(\"InvoiceYear\"))\n",
    "    mm_norm = _strip_leading_zero_num_str(values.get(\"InvoiceMonth\")) or values.get(\"InvoiceMonth\")\n",
    "    dd_norm = _strip_leading_zero_num_str(values.get(\"InvoiceDay\")) or values.get(\"InvoiceDay\")\n",
    "\n",
    "    # 2) 建立以固定順序輸出的 gt_parse\n",
    "    if str(doc_class) == \"triple_receipt\":\n",
    "        normalized_gt_parse = {\n",
    "            \"Doc_class\": \"triple_receipt\",\n",
    "            \"Rationale\": _get_ci(root, \"Rationale\"),\n",
    "            \"PrefixTwoLetters\": _get_ci(root, \"PrefixTwoLetters\"),\n",
    "            \"InvoiceNumber\": _get_ci(root, \"InvoiceNumber\"),\n",
    "            \"CompanyName\": _get_ci(root, \"CompanyName\"),\n",
    "            \"PhoneNumber\": _get_ci(root, \"PhoneNumber\"),\n",
    "            \"CompanyTaxIDNumber\": _get_ci(root, \"CompanyTaxIDNumber\"),\n",
    "            \"CompanyAddress\": _get_ci(root, \"CompanyAddress\"),\n",
    "            \"InvoiceYear\": _get_ci(root, \"InvoiceYear\"), # year_norm\n",
    "            \"InvoiceMonth\": mm_norm,\n",
    "            \"InvoiceDay\": dd_norm,\n",
    "            \"BuyerTaxIDNumber\": _get_ci(root, \"BuyerTaxIDNumber\"),\n",
    "            \"BuyerName\": _get_ci(root, \"BuyerName\"),\n",
    "            \"Abstract\": _get_ci(root, \"Abstract\"),\n",
    "            \"SalesTotalAmount\": st_norm if st_norm is not None else _get_ci(root, \"SalesTotalAmount\"),\n",
    "            \"SalesTax\": tax_norm if tax_norm is not None else _get_ci(root, \"SalesTax\"),\n",
    "            \"TotalAmount\": total_norm if total_norm is not None else _get_ci(root, \"TotalAmount\"),\n",
    "        }\n",
    "    else:  # 預設視為 triple_invoice（或其他類型也用這個順序以符合需求）\n",
    "        normalized_gt_parse = {\n",
    "            \"Doc_class\": \"triple_invoice\",\n",
    "            \"Rationale\": _get_ci(root, \"Rationale\"),\n",
    "            \"PrefixTwoLetters\": _get_ci(root, \"PrefixTwoLetters\"),\n",
    "            \"InvoiceNumber\": _get_ci(root, \"InvoiceNumber\"),\n",
    "            \"BuyerName\": _get_ci(root, \"BuyerName\"),\n",
    "            \"BuyerTaxIDNumber\": _get_ci(root, \"BuyerTaxIDNumber\"),\n",
    "            \"InvoiceYear\": _get_ci(root, \"InvoiceYear\"), # year_norm\n",
    "            \"InvoiceMonth\": mm_norm,\n",
    "            \"InvoiceDay\": dd_norm,\n",
    "            \"Abstract\": _get_ci(root, \"Abstract\"),\n",
    "            \"SalesTotalAmount\": st_norm if st_norm is not None else _get_ci(root, \"SalesTotalAmount\"),\n",
    "            \"SalesTax\": tax_norm if tax_norm is not None else _get_ci(root, \"SalesTax\"),\n",
    "            \"TotalAmount\": total_norm if total_norm is not None else _get_ci(root, \"TotalAmount\"),\n",
    "            \"CompanyName\": _get_ci(root, \"CompanyName\"),\n",
    "            \"CompanyTaxIDNumber\": _get_ci(root, \"CompanyTaxIDNumber\"),\n",
    "            \"PhoneNumber\": _get_ci(root, \"PhoneNumber\"),\n",
    "            \"CompanyAddress\": _get_ci(root, \"CompanyAddress\"),\n",
    "        }\n",
    "\n",
    "    normalized_obj = {\"gt_parse\": normalized_gt_parse}\n",
    "\n",
    "    # 3) 在結果中標出三個金額欄位的正規化值（如有）\n",
    "    if emit_normalized:\n",
    "        if year_norm is not None:  full_result[\"@normalized:InvoiceYear\"] = year_norm\n",
    "        if mm_norm is not None: full_result[\"@normalized:InvoiceMonth\"] = mm_norm\n",
    "        if dd_norm is not None:   full_result[\"@normalized:InvoiceDay\"] = dd_norm\n",
    "        if st_norm is not None:    full_result[\"@normalized:SalesTotalAmount\"] = st_norm\n",
    "        if tax_norm is not None:   full_result[\"@normalized:SalesTax\"] = tax_norm\n",
    "        if total_norm is not None: full_result[\"@normalized:TotalAmount\"] = total_norm\n",
    "\n",
    "    # 只輸出必填 + 規則 + 正規化資訊\n",
    "    if only_required_and_rules:\n",
    "        filtered = {k: v for k, v in full_result.items()\n",
    "                    if k in active_required or k.startswith(\"@rule:\") or k.startswith(\"@normalized:\") or (emit_info and k.startswith(\"@info:\"))}\n",
    "    else:\n",
    "        filtered = full_result\n",
    "\n",
    "    return (filtered, normalized_obj) if return_normalized_object else filtered\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf4621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{\n",
      "  \"PrefixTwoLetters\": true,\n",
      "  \"InvoiceNumber\": true,\n",
      "  \"InvoiceYear\": true,\n",
      "  \"InvoiceMonth\": true,\n",
      "  \"InvoiceDay\": true,\n",
      "  \"BuyerTaxIDNumber\": true,\n",
      "  \"CompanyTaxIDNumber\": true,\n",
      "  \"Abstract\": true,\n",
      "  \"SalesTotalAmount\": true,\n",
      "  \"SalesTax\": true,\n",
      "  \"TotalAmount\": true,\n",
      "  \"@rule:TotalAmount_equals_SalesTotal_plus_SalesTax\": true\n",
      "}\n",
      "{\n",
      "  \"gt_parse\": {\n",
      "    \"Doc_class\": \"triple_receipt\",\n",
      "    \"Rationale\": \"收銀機統一發票，包含發票號碼、日期、統編、買受人、品名、數量、單價、小計、銷售額、營業稅、總計等\",\n",
      "    \"PrefixTwoLetters\": \"TC\",\n",
      "    \"InvoiceNumber\": \"23747161\",\n",
      "    \"CompanyName\": \"柏格文具禮品股份有限公司\",\n",
      "    \"PhoneNumber\": \"\",\n",
      "    \"CompanyTaxIDNumber\": \"28652798\",\n",
      "    \"CompanyAddress\": \"710台南市永康區崑山街183巷23號\",\n",
      "    \"InvoiceYear\": \"110\",\n",
      "    \"InvoiceMonth\": \"12\",\n",
      "    \"InvoiceDay\": \"15\",\n",
      "    \"BuyerTaxIDNumber\": \"53812386\",\n",
      "    \"BuyerName\": \"53812386\",\n",
      "    \"Abstract\": \"手提袋 172 55.22 9,498\",\n",
      "    \"SalesTotalAmount\": \"9498\",\n",
      "    \"SalesTax\": \"475\",\n",
      "    \"TotalAmount\": \"9973\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "FastVisionModel.for_inference(model)  # inference 模式\n",
    "\n",
    "\n",
    "def chat_once(image):\n",
    "    instruction = \"你是發票/單據分類器與結構化抽取器，請辨識這張文件\"\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "            {\"type\": \"image\"},\n",
    "            {\"type\": \"text\", \"text\": instruction}\n",
    "        ]}\n",
    "    ]\n",
    "\n",
    "    # 準備輸入\n",
    "    input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "    inputs = tokenizer(\n",
    "        image,\n",
    "        input_text,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    # 產生（不使用 streamer，改成一次取回）\n",
    "    gen_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=1024,\n",
    "        use_cache=True,\n",
    "        temperature=0.1,\n",
    "        min_p=0.1,\n",
    "        do_sample=True,              # 若你想要可重現，可改成 False\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "    )\n",
    "\n",
    "    # 只取「模型新產生」的 token，排除提示部分\n",
    "    prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "    new_token_ids = gen_ids[0, prompt_len:]\n",
    "\n",
    "    output_text = tokenizer.decode(new_token_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "    try:\n",
    "        #print(\"json is good!\")\n",
    "        result = json.loads(output_text)\n",
    "    except Exception:\n",
    "        #print(\"bad json is repaired!\")\n",
    "        result, obj, logs = repair_json(output_text)\n",
    "\n",
    "    #print(type(result), result)\n",
    "    #result = json.loads(result)\n",
    "    #print(type(result), json.dumps(result['gt_parse'], ensure_ascii=False, indent=2))\n",
    "    return result\n",
    "\n",
    "image = Image.open(\"./invoice2.jpg\").convert(\"RGB\")\n",
    "input_string = json.loads(chat_once(image))\n",
    "input_string['gt_parse']['doc_class'] = \"triple_receipt\" # triple_receipt, triple_invoice\n",
    "compliance, edit_string = check_compliance(input_string)\n",
    "print(type(compliance))\n",
    "print(json.dumps(compliance, ensure_ascii=False, indent=2))\n",
    "print(json.dumps(edit_string, ensure_ascii=False, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52244f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total entries found: 1511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:   0%|          | 1/1511 [00:17<7:29:47, 17.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] photo_20240920015837.json -> C:/Users/user/pythonproject/AllDataset/VAT-OCR\\triple_receipt\\label\\train_new\\photo_20240920015837.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:   0%|          | 2/1511 [00:36<7:45:20, 18.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] photo_20240920033442.json -> C:/Users/user/pythonproject/AllDataset/VAT-OCR\\triple_receipt\\label\\train_new\\photo_20240920033442.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:   0%|          | 2/1511 [00:40<8:25:44, 20.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 33\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# 載入影像 → 丟到你的模型\u001b[39;00m\n\u001b[32m     32\u001b[39m image = Image.open(img_path).convert(\u001b[33m\"\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m model_output = \u001b[43mchat_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# 你的函式，回傳可被 json.loads 的字串\u001b[39;00m\n\u001b[32m     34\u001b[39m input_string = json.loads(model_output)\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# 指定 doc_class（你的 check_compliance 會大小寫不敏感）\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mchat_once\u001b[39m\u001b[34m(image)\u001b[39m\n\u001b[32m     20\u001b[39m inputs = tokenizer(\n\u001b[32m     21\u001b[39m     image,\n\u001b[32m     22\u001b[39m     input_text,\n\u001b[32m     23\u001b[39m     add_special_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     24\u001b[39m     return_tensors=\u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     25\u001b[39m ).to(\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 產生（不使用 streamer，改成一次取回）\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m gen_ids = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# 若你想要可重現，可改成 False\u001b[39;49;00m\n\u001b[32m     35\u001b[39m \u001b[43m    \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# 只取「模型新產生」的 token，排除提示部分\u001b[39;00m\n\u001b[32m     40\u001b[39m prompt_len = inputs[\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m].shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\peft\\peft_model.py:886\u001b[39m, in \u001b[36mPeftModel.generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    884\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._enable_peft_forward_hooks(*args, **kwargs):\n\u001b[32m    885\u001b[39m     kwargs = {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.special_peft_forward_args}\n\u001b[32m--> \u001b[39m\u001b[32m886\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_base_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\unsloth\\models\\vision.py:231\u001b[39m, in \u001b[36munsloth_base_fast_generate\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode(), autocaster:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_old_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    233\u001b[39m FastBaseModel.for_training(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\utils\\_contextlib.py:120\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\transformers\\generation\\utils.py:2539\u001b[39m, in \u001b[36mGenerationMixin.generate\u001b[39m\u001b[34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, use_model_defaults, custom_generate, **kwargs)\u001b[39m\n\u001b[32m   2528\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m GenerationMixin.generate(\n\u001b[32m   2529\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   2530\u001b[39m         inputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2534\u001b[39m         **kwargs,\n\u001b[32m   2535\u001b[39m     )\n\u001b[32m   2537\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.SAMPLE, GenerationMode.GREEDY_SEARCH):\n\u001b[32m   2538\u001b[39m     \u001b[38;5;66;03m# 11. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2539\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2540\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2541\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2542\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2543\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2544\u001b[39m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m=\u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2545\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2546\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2547\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2549\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode.BEAM_SAMPLE, GenerationMode.BEAM_SEARCH):\n\u001b[32m   2550\u001b[39m     \u001b[38;5;66;03m# 11. run beam sample\u001b[39;00m\n\u001b[32m   2551\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._beam_search(\n\u001b[32m   2552\u001b[39m         input_ids,\n\u001b[32m   2553\u001b[39m         logits_processor=prepared_logits_processor,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m         **model_kwargs,\n\u001b[32m   2558\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\transformers\\generation\\utils.py:2870\u001b[39m, in \u001b[36mGenerationMixin._sample\u001b[39m\u001b[34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[39m\n\u001b[32m   2868\u001b[39m     is_prefill = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m   2869\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2870\u001b[39m     outputs = \u001b[43mmodel_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   2872\u001b[39m \u001b[38;5;66;03m# synced_gpus: don't waste resources running the code we don't need; kwargs must be updated before skipping\u001b[39;00m\n\u001b[32m   2873\u001b[39m model_kwargs = \u001b[38;5;28mself\u001b[39m._update_model_kwargs_for_generation(\n\u001b[32m   2874\u001b[39m     outputs,\n\u001b[32m   2875\u001b[39m     model_kwargs,\n\u001b[32m   2876\u001b[39m     is_encoder_decoder=\u001b[38;5;28mself\u001b[39m.config.is_encoder_decoder,\n\u001b[32m   2877\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\pythonproject\\VAT-OCR\\unsloth_compiled_cache\\unsloth_compiled_module_qwen2_5_vl.py:901\u001b[39m, in \u001b[36mQwen2_5_VLForConditionalGeneration.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, rope_deltas, cache_position, second_per_grid_ts, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    880\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m    881\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    882\u001b[39m     input_ids: torch.LongTensor = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    899\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    900\u001b[39m ) -> Union[\u001b[38;5;28mtuple\u001b[39m, Qwen2_5_VLCausalLMOutputWithPast]:\n\u001b[32m--> \u001b[39m\u001b[32m901\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQwen2_5_VLForConditionalGeneration_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpixel_values_videos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_grid_thw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideo_grid_thw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrope_deltas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecond_per_grid_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_to_keep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\_dynamo\\external_utils.py:198\u001b[39m, in \u001b[36mget_nonrecursive_disable_wrapper.<locals>.nonrecursive_disable_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    196\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(fn)\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnonrecursive_disable_wrapper\u001b[39m(*args: _P.args, **kwargs: _P.kwargs) -> _R:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\transformers\\utils\\generic.py:940\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    939\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    942\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\pythonproject\\VAT-OCR\\unsloth_compiled_cache\\unsloth_compiled_module_qwen2_5_vl.py:694\u001b[39m, in \u001b[36mQwen2_5_VLForConditionalGeneration_forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, rope_deltas, cache_position, second_per_grid_ts, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    689\u001b[39m output_attentions = output_attentions \u001b[38;5;28;01mif\u001b[39;00m output_attentions \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_attentions\n\u001b[32m    690\u001b[39m output_hidden_states = (\n\u001b[32m    691\u001b[39m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.output_hidden_states\n\u001b[32m    692\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m694\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpixel_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpixel_values_videos\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpixel_values_videos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m    \u001b[49m\u001b[43mimage_grid_thw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mimage_grid_thw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvideo_grid_thw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvideo_grid_thw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m    \u001b[49m\u001b[43msecond_per_grid_ts\u001b[49m\u001b[43m=\u001b[49m\u001b[43msecond_per_grid_ts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    704\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    706\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    709\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    710\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m hidden_states = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    715\u001b[39m \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\transformers\\models\\qwen2_5_vl\\modeling_qwen2_5_vl.py:1313\u001b[39m, in \u001b[36mQwen2_5_VLModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, pixel_values, pixel_values_videos, image_grid_thw, video_grid_thw, rope_deltas, cache_position, second_per_grid_ts, **kwargs)\u001b[39m\n\u001b[32m   1310\u001b[39m         delta = delta.repeat_interleave(batch_size // delta.shape[\u001b[32m0\u001b[39m], dim=\u001b[32m1\u001b[39m)\n\u001b[32m   1311\u001b[39m         position_ids += delta.to(position_ids.device)\n\u001b[32m-> \u001b[39m\u001b[32m1313\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlanguage_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1314\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1317\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1318\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1319\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1320\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1327\u001b[39m output = Qwen2_5_VLModelOutputWithPast(\n\u001b[32m   1328\u001b[39m     last_hidden_state=outputs.last_hidden_state,\n\u001b[32m   1329\u001b[39m     past_key_values=outputs.past_key_values,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1332\u001b[39m     rope_deltas=\u001b[38;5;28mself\u001b[39m.rope_deltas,\n\u001b[32m   1333\u001b[39m )\n\u001b[32m   1334\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;28;01melse\u001b[39;00m output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\transformers\\models\\qwen2_5_vl\\modeling_qwen2_5_vl.py:902\u001b[39m, in \u001b[36mQwen2_5_VLTextModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position, **kwargs)\u001b[39m\n\u001b[32m    899\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states:\n\u001b[32m    900\u001b[39m     all_hidden_states += (hidden_states,)\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m layer_outputs = \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    903\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    904\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcausal_mask_mapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdecoder_layer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mattention_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    905\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtext_position_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    906\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    907\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    908\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    909\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    910\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_embeddings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    911\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    912\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    914\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\transformers\\modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\transformers\\models\\qwen2_5_vl\\modeling_qwen2_5_vl.py:769\u001b[39m, in \u001b[36mQwen2_5_VLDecoderLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, position_ids, past_key_values, output_attentions, use_cache, cache_position, position_embeddings, **kwargs)\u001b[39m\n\u001b[32m    767\u001b[39m residual = hidden_states\n\u001b[32m    768\u001b[39m hidden_states = \u001b[38;5;28mself\u001b[39m.post_attention_layernorm(hidden_states)\n\u001b[32m--> \u001b[39m\u001b[32m769\u001b[39m hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    770\u001b[39m hidden_states = residual + hidden_states\n\u001b[32m    772\u001b[39m outputs = (hidden_states,)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\pythonproject\\VAT-OCR\\unsloth_compiled_cache\\unsloth_compiled_module_qwen2_5_vl.py:462\u001b[39m, in \u001b[36mQwen2MLP.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m--> \u001b[39m\u001b[32m462\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mQwen2MLP_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:736\u001b[39m, in \u001b[36m_TorchDynamoContext.__call__.<locals>.compile_wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    733\u001b[39m _maybe_set_eval_frame(_callback_from_stance(callback))\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    737\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Unsupported \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    738\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config.verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\pythonproject\\VAT-OCR\\unsloth_compiled_cache\\unsloth_compiled_module_qwen2_5_vl.py:445\u001b[39m, in \u001b[36mQwen2MLP_forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    441\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, position_ids):\n\u001b[32m    442\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Qwen2_5_VLRotaryEmbedding_forward(\u001b[38;5;28mself\u001b[39m, x, position_ids)\n\u001b[32m--> \u001b[39m\u001b[32m445\u001b[39m \u001b[38;5;129m@torch\u001b[39m.compile(fullgraph = \u001b[38;5;28;01mFalse\u001b[39;00m, dynamic = \u001b[38;5;28;01mTrue\u001b[39;00m, options = torch_compile_options)\n\u001b[32m    446\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mQwen2MLP_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m    447\u001b[39m     down_proj = \u001b[38;5;28mself\u001b[39m.down_proj(\u001b[38;5;28mself\u001b[39m.act_fn(\u001b[38;5;28mself\u001b[39m.gate_proj(x)) * \u001b[38;5;28mself\u001b[39m.up_proj(x))\n\u001b[32m    448\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m down_proj\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:929\u001b[39m, in \u001b[36mDisableContext.__call__.<locals>._fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    927\u001b[39m _maybe_set_eval_frame(_callback_from_stance(\u001b[38;5;28mself\u001b[39m.callback))\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m929\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    931\u001b[39m     set_eval_frame(\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\_functorch\\aot_autograd.py:1241\u001b[39m, in \u001b[36maot_module_simplified.<locals>.forward\u001b[39m\u001b[34m(*runtime_args)\u001b[39m\n\u001b[32m   1239\u001b[39m full_args.extend(params_flat)\n\u001b[32m   1240\u001b[39m full_args.extend(runtime_args)\n\u001b[32m-> \u001b[39m\u001b[32m1241\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\runtime_wrappers.py:384\u001b[39m, in \u001b[36m_create_runtime_wrapper.<locals>.runtime_wrapper\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    382\u001b[39m         torch._C._set_grad_enabled(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    383\u001b[39m     record_runtime_wrapper_prologue_exit(cm)\n\u001b[32m--> \u001b[39m\u001b[32m384\u001b[39m     all_outs = \u001b[43mcall_func_at_runtime_with_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompiled_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable_amp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdisable_amp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteal_args\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    386\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    388\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m grad_enabled:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\utils.py:126\u001b[39m, in \u001b[36mcall_func_at_runtime_with_args\u001b[39m\u001b[34m(f, args, steal_args, disable_amp)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(f, \u001b[33m\"\u001b[39m\u001b[33m_boxed_call\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m         out = normalize_as_list(\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    128\u001b[39m         \u001b[38;5;66;03m# TODO: Please remove soon\u001b[39;00m\n\u001b[32m    129\u001b[39m         \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670\u001b[39;00m\n\u001b[32m    130\u001b[39m         warnings.warn(\n\u001b[32m    131\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYour compiler for AOTAutograd is returning a function that doesn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt take boxed arguments. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    132\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mPlease wrap it with functorch.compile.make_boxed_func or handle the boxed arguments yourself. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    133\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mSee https://github.com/pytorch/pytorch/pull/83137#issuecomment-1211320670 for rationale.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    134\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\_functorch\\_aot_autograd\\runtime_wrappers.py:556\u001b[39m, in \u001b[36mFunctionalizedRngRuntimeWrapper.post_compile.<locals>.wrapper\u001b[39m\u001b[34m(runtime_args)\u001b[39m\n\u001b[32m    549\u001b[39m     out = \u001b[38;5;28mself\u001b[39m._functionalized_rng_runtime_epilogue(\n\u001b[32m    550\u001b[39m         runtime_metadata,\n\u001b[32m    551\u001b[39m         out,\n\u001b[32m    552\u001b[39m         \u001b[38;5;66;03m# TODO: this won't be right for the backward when we convert the call_compiled_backward to use the wrapper\u001b[39;00m\n\u001b[32m    553\u001b[39m         runtime_metadata.num_forward_returns,\n\u001b[32m    554\u001b[39m     )\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcompiled_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruntime_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\_inductor\\output_code.py:584\u001b[39m, in \u001b[36mCompiledFxGraph.__call__\u001b[39m\u001b[34m(self, inputs)\u001b[39m\n\u001b[32m    582\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.current_callable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcurrent_callable\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    585\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    586\u001b[39m     get_runtime_metrics_context().finish()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\torch\\_inductor\\utils.py:2716\u001b[39m, in \u001b[36malign_inputs_from_check_idxs.<locals>.run\u001b[39m\u001b[34m(new_inputs)\u001b[39m\n\u001b[32m   2712\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(new_inputs: \u001b[38;5;28mlist\u001b[39m[InputType]) -> Any:\n\u001b[32m   2713\u001b[39m     old_tensors, new_tensors = copy_misaligned_inputs(\n\u001b[32m   2714\u001b[39m         new_inputs, inputs_to_check, mutated_input_idxs\n\u001b[32m   2715\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2716\u001b[39m     out = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2718\u001b[39m     \u001b[38;5;66;03m# If a mutated tensor was cloned to be aligned, we need to reflect back the mutation to the\u001b[39;00m\n\u001b[32m   2719\u001b[39m     \u001b[38;5;66;03m# original tensor.\u001b[39;00m\n\u001b[32m   2720\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(old_tensors):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Temp\\torchinductor_user\\xw\\cxwy5njgyvpphv2lcaw5ztrn4pegzaxdjz7irelb7jrq2oetowdo.py:303\u001b[39m, in \u001b[36mcall\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m    301\u001b[39m buf6 = alloc_from_pool(pool0, \u001b[32m0\u001b[39m, torch.bfloat16, (\u001b[32m1\u001b[39m, \u001b[32m16\u001b[39m), (\u001b[32m16\u001b[39m, \u001b[32m1\u001b[39m))\n\u001b[32m    302\u001b[39m \u001b[38;5;66;03m# Topologically Sorted Source Nodes: [xA], Original ATen: [aten._to_copy, aten.mm]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m303\u001b[39m \u001b[43mextern_kernels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreinterpret_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg1_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m3584\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3584\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuf5\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbuf6\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    304\u001b[39m buf7 = pool1  \u001b[38;5;66;03m# alloc\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m# Topologically Sorted Source Nodes: [addmm], Original ATen: [aten._to_copy]\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from PIL import Image  # 新增：載入影像\n",
    "\n",
    "# 你現有的設定\n",
    "doc_class = \"triple_receipt\"  # triple_receipt, triple_invoice\n",
    "root_dir = os.path.join(\"C:/Users/user/pythonproject/AllDataset/VAT-OCR\", doc_class)\n",
    "mode = 'train'  # 'train' or 'test'\n",
    "\n",
    "label_dir = os.path.join(root_dir, 'label', mode)\n",
    "image_dir = os.path.join(root_dir, 'image')\n",
    "\n",
    "# 目的地資料夾：<mode>_new / <mode>_fail\n",
    "out_base_dir = os.path.join(root_dir, 'label')\n",
    "out_dir_pass = os.path.join(out_base_dir, f'{mode}_new')   # e.g., train_new\n",
    "out_dir_fail = os.path.join(out_base_dir, f'{mode}_fail')  # e.g., train_fail\n",
    "os.makedirs(out_dir_pass, exist_ok=True)\n",
    "os.makedirs(out_dir_fail, exist_ok=True)\n",
    "\n",
    "entries = [os.path.splitext(f)[0] + '.json' for f in os.listdir(image_dir) if f.lower().endswith('.jpg')]\n",
    "print(f\"Total entries found: {len(entries)}\")\n",
    "\n",
    "for entry in tqdm(entries, desc=\"Processing entries\"):\n",
    "    try:\n",
    "        base = os.path.splitext(entry)[0]\n",
    "        json_path = os.path.join(label_dir, entry)\n",
    "        img_name = base + '.jpg'\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "\n",
    "        # 載入影像 → 丟到你的模型\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        model_output = chat_once(image)  # 你的函式，回傳可被 json.loads 的字串\n",
    "        input_string = json.loads(model_output)\n",
    "\n",
    "        # 指定 doc_class（你的 check_compliance 會大小寫不敏感）\n",
    "        if 'gt_parse' not in input_string:\n",
    "            input_string['gt_parse'] = {}\n",
    "        input_string['gt_parse']['doc_class'] = doc_class\n",
    "\n",
    "        # 檢核與正規化（你的 check_compliance 會回傳 (compliance, edit_string)）\n",
    "        compliance, edit_string = check_compliance(input_string)\n",
    "\n",
    "        # 判斷是否所有布林值皆 True（忽略非布林的 @normalized:XXX 等）\n",
    "        bool_flags = [v for v in compliance.values() if isinstance(v, bool)]\n",
    "        all_pass = len(bool_flags) > 0 and all(bool_flags)\n",
    "\n",
    "        # 目的地：全通過 → <mode>_new；任一 False → <mode>_fail\n",
    "        dest_dir = out_dir_pass if all_pass else out_dir_fail\n",
    "        dest_path = os.path.join(dest_dir, entry)  # 沿用原本 json 檔名\n",
    "\n",
    "        # 寫出正規化後的 edit_string\n",
    "        with open(dest_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(edit_string['gt_parse'], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        # 可選：印出簡短紀錄\n",
    "        # 也可以印失敗鍵：failed = [k for k,v in compliance.items() if isinstance(v,bool) and not v]\n",
    "        print(f\"[{'OK' if all_pass else 'FAIL'}] {entry} -> {dest_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # 若某檔處理失敗，丟去 fail 夾並記錄錯誤\n",
    "        dest_path = os.path.join(out_dir_fail, entry)\n",
    "        try:\n",
    "            # 若 edit_string 沒成功產生，就把模型原輸出包裝一下存檔，避免遺失樣本\n",
    "            payload = edit_string if 'edit_string' in locals() else {\"raw\": model_output if 'model_output' in locals() else None}\n",
    "            with open(dest_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "        except Exception:\n",
    "            pass\n",
    "        print(f\"[ERROR] {entry}: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7595682",
   "metadata": {},
   "source": [
    "(old inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625160c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gt_parse': {'Other': ['柏格文具禮品股份有限公司', '台南市永康區崙山街183巷23號', '統編', '710'], 'Tail': {'SalesTax': '475', 'SalesTotalAmount': '9498', 'TotalAmount': '9973'}, 'body': {'BuyerTaxIDNumber': '53812386', 'CompanyTaxIDNumber': '28652798'}, 'header': {'InvoiceDay': '15', 'InvoiceMonth': '12', 'InvoiceYear': '110', 'PrefixTwoLetters': 'TC'}}}<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"./invoice.jpg\").convert(\"RGB\")\n",
    "instruction = \"你是發票/單據分類器與結構化抽取器，請辨識這張文件\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
