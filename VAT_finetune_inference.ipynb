{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edcc16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Exception in thread Thread-4 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 772, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa4 in position 7: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0916 12:07:13.500000 39828 site-packages\\torch\\distributed\\elastic\\multiprocessing\\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\VAT\\Lib\\site-packages\\unsloth_zoo\\gradient_checkpointing.py:339: UserWarning: expandable_segments not supported on this platform (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\c10/cuda/CUDAAllocatorConfig.h:35.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE}:{i}\") for i in range(n_gpus)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.9.4: Fast Qwen2_5_Vl patching. Transformers: 4.56.1.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070. Num GPUs = 1. Max memory: 11.994 GB. Platform: Windows.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.32.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "if True:\n",
    "    from unsloth import FastVisionModel\n",
    "    model, tokenizer = FastVisionModel.from_pretrained(\n",
    "        model_name = \"VAT_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        load_in_4bit = True, # Set to False for 16bit LoRA\n",
    "    )\n",
    "    FastVisionModel.for_inference(model) # Enable for inference!\n",
    "\n",
    "import re, json, ast\n",
    "from typing import Tuple, Any, List, Optional\n",
    "\n",
    "def repair_json(s: str, schema: Optional[dict] = None) -> Tuple[str, Any, List[str]]:\n",
    "    \"\"\"\n",
    "    å°‡ã€Œå¹¾ä¹ JSONã€çš„å­—ä¸²ä¿®å¾©æˆåˆæ³• JSONã€‚\n",
    "    å›å‚³: (fixed_text, obj, logs)\n",
    "      fixed_text: ä¿®å¾©å¾Œçš„ JSON å­—ä¸²\n",
    "      obj:        å°æ‡‰çš„ Python ç‰©ä»¶ (dict/list)\n",
    "      logs:       ä¿®å¾©æ­¥é©Ÿç´€éŒ„\n",
    "    \"\"\"\n",
    "    logs: List[str] = []\n",
    "    text = s.strip()\n",
    "\n",
    "    # 0) å»æ‰ ```json ... ``` æˆ–ä¸€èˆ¬ ``` å€å¡Šå¤–æ®¼\n",
    "    if \"```\" in text:\n",
    "        text = re.sub(r\"```(?:json|JSON)?\", \"\", text)\n",
    "        text = text.replace(\"```\", \"\")\n",
    "        text = text.strip()\n",
    "        logs.append(\"removed code fences\")\n",
    "\n",
    "    # 1) åªæ“·å–æœ€å¤–å±¤ {...} æˆ– [...]\n",
    "    def _extract_json_region(t: str) -> str:\n",
    "        lb, rb = t.find(\"{\"), t.rfind(\"}\")\n",
    "        if lb != -1 and rb != -1 and rb > lb:\n",
    "            return t[lb:rb+1]\n",
    "        lb, rb = t.find(\"[\"), t.rfind(\"]\")\n",
    "        if lb != -1 and rb != -1 and rb > lb:\n",
    "            return t[lb:rb+1]\n",
    "        return t\n",
    "\n",
    "    text2 = _extract_json_region(text)\n",
    "    if text2 != text:\n",
    "        logs.append(\"extracted outer JSON-like region\")\n",
    "        text = text2\n",
    "\n",
    "    # 2) å˜—è©¦æ¨™æº– JSON\n",
    "    try:\n",
    "        obj = json.loads(text)\n",
    "        logs.append(\"parsed by json\")\n",
    "        if schema:\n",
    "            from jsonschema import validate\n",
    "            validate(obj, schema); logs.append(\"validated by jsonschema\")\n",
    "        return json.dumps(obj, ensure_ascii=False, indent=2), obj, logs\n",
    "    except Exception as e:\n",
    "        logs.append(f\"json.loads failed: {e}\")\n",
    "\n",
    "    # 3) ç”¨ ast.literal_eval åƒå–®å¼•è™Ÿ/å°¾é€—è™Ÿ ç­‰ Python å­—é¢é‡\n",
    "    try:\n",
    "        obj = ast.literal_eval(text)\n",
    "        logs.append(\"parsed by ast.literal_eval\")\n",
    "        if schema:\n",
    "            from jsonschema import validate\n",
    "            validate(obj, schema); logs.append(\"validated by jsonschema\")\n",
    "        return json.dumps(obj, ensure_ascii=False, indent=2), obj, logs\n",
    "    except Exception as e:\n",
    "        logs.append(f\"ast.literal_eval failed: {e}\")\n",
    "\n",
    "    # 4) å¸¸è¦‹ä¿®è£œï¼šå½å¼•è™Ÿâ†’ç›´å¼•è™Ÿã€True/False/Noneâ†’JSONã€åˆªå°¾é€—è™Ÿã€å–®å¼•è™Ÿâ†’é›™å¼•è™Ÿ\n",
    "    fixed = text.translate(str.maketrans({\n",
    "        \"\\u201c\": '\"', \"\\u201d\": '\"', \"\\u2018\": \"'\", \"\\u2019\": \"'\",\n",
    "    }))\n",
    "    if fixed != text:\n",
    "        logs.append(\"normalized curly quotes\")\n",
    "\n",
    "    # Python å¸¸é‡ â†’ JSON å¸¸é‡\n",
    "    fixed2 = re.sub(r'(?<!\")\\bTrue\\b(?!\")', \"true\", fixed)\n",
    "    fixed2 = re.sub(r'(?<!\")\\bFalse\\b(?!\")', \"false\", fixed2)\n",
    "    fixed2 = re.sub(r'(?<!\")\\bNone\\b(?!\")', \"null\", fixed2)\n",
    "    if fixed2 != fixed:\n",
    "        logs.append(\"converted Python literals to JSON\")\n",
    "    fixed = fixed2\n",
    "\n",
    "    # ç§»é™¤å°¾é€—è™Ÿ\n",
    "    no_trailing_commas = re.sub(r\",\\s*([}\\]])\", r\"\\1\", fixed)\n",
    "    if no_trailing_commas != fixed:\n",
    "        logs.append(\"removed trailing commas\")\n",
    "    fixed = no_trailing_commas\n",
    "\n",
    "    # ç²—ç•¥ï¼šå–®å¼•è™Ÿ â†’ é›™å¼•è™Ÿï¼ˆåœ¨ä¸­æ–‡å…§å®¹é€šå¸¸å®‰å…¨ï¼‰\n",
    "    dq = re.sub(r\"(?<!\\\\)'\", '\"', fixed)\n",
    "    if dq != fixed:\n",
    "        logs.append(\"replaced single quotes with double quotes\")\n",
    "    fixed = dq\n",
    "\n",
    "    # 5) æœ€çµ‚å˜—è©¦æ¨™æº– JSON\n",
    "    try:\n",
    "        obj = json.loads(fixed)\n",
    "        logs.append(\"fixed manually then parsed by json\")\n",
    "        if schema:\n",
    "            from jsonschema import validate\n",
    "            validate(obj, schema); logs.append(\"validated by jsonschema\")\n",
    "        return json.dumps(obj, ensure_ascii=False, indent=2), obj, logs\n",
    "    except Exception as e:\n",
    "        logs.append(f\"final json.loads failed: {e}\")\n",
    "        # å…œåº•ï¼šåŒ… raw\n",
    "        fallback = {\"raw\": s}\n",
    "        if schema:\n",
    "            logs.append(\"returned raw because schema validation/parse failed\")\n",
    "        return json.dumps(fallback, ensure_ascii=False, indent=2), fallback, logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2bf4621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"gt_parse\": {\n",
      "    \"Other\": [\n",
      "      \"æŸæ ¼æ–‡å…·ç¦®å“è‚¡ä»½æœ‰é™å…¬å¸\",\n",
      "      \"çµ±ç·¨\",\n",
      "      \"710å°å—å¸‚æ°¸åº·å€å´‘å±±è¡—183å··23è™Ÿ\"\n",
      "    ],\n",
      "    \"Tail\": {\n",
      "      \"SalesTax\": \"475\",\n",
      "      \"SalesTotalAmount\": \"9498\",\n",
      "      \"TotalAmount\": \"9973\"\n",
      "    },\n",
      "    \"body\": {\n",
      "      \"BuyerTaxIDNumber\": \"53812386\",\n",
      "      \"CompanyTaxIDNumber\": \"28652798\",\n",
      "      \"InvoiceDay\": \"15\",\n",
      "      \"InvoiceMonth\": \"12\",\n",
      "      \"InvoiceYear\": \"110\",\n",
      "      \"PhoneNumber\": \"06-2059968\"\n",
      "    },\n",
      "    \"header\": {\n",
      "      \"InvoiceNumber\": \"23747161\",\n",
      "      \"PrefixTwoLetters\": \"TC\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import Image\n",
    "\n",
    "FastVisionModel.for_inference(model)  # inference æ¨¡å¼\n",
    "\n",
    "image = Image.open(\"./invoice2.jpg\").convert(\"RGB\")\n",
    "\n",
    "instruction = \"ä½ æ˜¯ç™¼ç¥¨/å–®æ“šåˆ†é¡å™¨èˆ‡çµæ§‹åŒ–æŠ½å–å™¨ï¼Œè«‹è¾¨è­˜é€™å¼µæ–‡ä»¶\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "\n",
    "# æº–å‚™è¼¸å…¥\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt=True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens=False,\n",
    "    return_tensors=\"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "# ç”¢ç”Ÿï¼ˆä¸ä½¿ç”¨ streamerï¼Œæ”¹æˆä¸€æ¬¡å–å›ï¼‰\n",
    "gen_ids = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=256,\n",
    "    use_cache=True,\n",
    "    temperature=0.1,\n",
    "    min_p=0.1,\n",
    "    do_sample=True,              # è‹¥ä½ æƒ³è¦å¯é‡ç¾ï¼Œå¯æ”¹æˆ False\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# åªå–ã€Œæ¨¡å‹æ–°ç”¢ç”Ÿã€çš„ tokenï¼Œæ’é™¤æç¤ºéƒ¨åˆ†\n",
    "prompt_len = inputs[\"input_ids\"].shape[1]\n",
    "new_token_ids = gen_ids[0, prompt_len:]\n",
    "\n",
    "output_text = tokenizer.decode(new_token_ids, skip_special_tokens=True).strip()\n",
    "\n",
    "try:\n",
    "    result = json.loads(output_text)\n",
    "except Exception:\n",
    "    result, obj, logs = repair_json(output_text)\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52244f62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f7595682",
   "metadata": {},
   "source": [
    "(old inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625160c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gt_parse': {'Other': ['æŸæ ¼æ–‡å…·ç¦®å“è‚¡ä»½æœ‰é™å…¬å¸', 'å°å—å¸‚æ°¸åº·å€å´™å±±è¡—183å··23è™Ÿ', 'çµ±ç·¨', '710'], 'Tail': {'SalesTax': '475', 'SalesTotalAmount': '9498', 'TotalAmount': '9973'}, 'body': {'BuyerTaxIDNumber': '53812386', 'CompanyTaxIDNumber': '28652798'}, 'header': {'InvoiceDay': '15', 'InvoiceMonth': '12', 'InvoiceYear': '110', 'PrefixTwoLetters': 'TC'}}}<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image = Image.open(\"./invoice.jpg\").convert(\"RGB\")\n",
    "instruction = \"ä½ æ˜¯ç™¼ç¥¨/å–®æ“šåˆ†é¡å™¨èˆ‡çµæ§‹åŒ–æŠ½å–å™¨ï¼Œè«‹è¾¨è­˜é€™å¼µæ–‡ä»¶\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": [\n",
    "        {\"type\": \"image\"},\n",
    "        {\"type\": \"text\", \"text\": instruction}\n",
    "    ]}\n",
    "]\n",
    "input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)\n",
    "inputs = tokenizer(\n",
    "    image,\n",
    "    input_text,\n",
    "    add_special_tokens = False,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 256,\n",
    "                   use_cache = True, temperature = 1.5, min_p = 0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VAT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
